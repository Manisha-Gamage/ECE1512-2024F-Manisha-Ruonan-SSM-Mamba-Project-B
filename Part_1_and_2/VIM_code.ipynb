{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16713230-04b2-4171-b47d-85d081319aef",
   "metadata": {},
   "source": [
    "## Efficieny improvement to Vision Mamba \n",
    "This experiment is conducted by training full image set and then also dropping patches of the images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f076851b-4cdb-4521-b357-6cc0b96e956e",
   "metadata": {},
   "source": [
    "Structure and the Mamba model in this code is inspired by the \"L. Zhu, B. Liao, Q. Zhang, X. Wang, W. Liu, and X. Wang, “Vision Mamba: Efficient Visual\n",
    "Representation Learning with Bidirectional State Space Model,” Computer Vision and Pattern\n",
    "Recognition, 1 2024. [Online]. Available: https://github.com/hustvl/Vim\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e451e89f-de39-4fd1-b048-a4b167d94acb",
   "metadata": {},
   "source": [
    "### Download the Cats and Dogs data from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ac9124-7905-4f18-8517-0ed0d79ea114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import kagglehub\n",
    "\n",
    "# # Download the Cats vs Dogs dataset\n",
    "# path = kagglehub.dataset_download(\"abhinavnayak/catsvdogs-transformed\")\n",
    "\n",
    "# print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ac358d-1afa-46b7-8257-9468d52485b1",
   "metadata": {},
   "source": [
    "                  ###################################### Code Starts here ##############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb6a148-1a1f-4571-8186-edb0c6243707",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a0cf53-c43c-41d1-abea-3b72a221da48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import json\n",
    "import utils\n",
    "import sys\n",
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import models_mamba\n",
    "\n",
    "from pathlib import Path\n",
    "from timm.data import Mixup\n",
    "from timm.models import create_model\n",
    "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
    "from timm.scheduler import create_scheduler\n",
    "from timm.optim import create_optimizer\n",
    "from timm.utils import NativeScaler, get_state_dict, ModelEma\n",
    "\n",
    "# from datasets import build_dataset\n",
    "from engine import train_one_epoch, evaluate\n",
    "from losses import DistillationLoss\n",
    "from samplers import RASampler\n",
    "from augment import new_data_aug_generator\n",
    "from contextlib import suppress\n",
    "\n",
    "from torchvision import transforms\n",
    "from fvcore.nn import FlopCountAnalysis\n",
    "\n",
    "\n",
    "# log about\n",
    "import mlflow\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e07a69-6c0e-48ae-a68d-9f12d877e313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args_parser():\n",
    "    # Remove the Jupyter-specific arguments\n",
    "    sys.argv = sys.argv[:1]  # Keep only the script name (the first argument)\n",
    "    \n",
    "    parser = argparse.ArgumentParser('DeiT training and evaluation script', add_help=False)\n",
    "    parser.add_argument('--batch-size', default=64, type=int)\n",
    "    parser.add_argument('--epochs', default=20, type=int)\n",
    "    parser.add_argument('--bce-loss', action='store_true')\n",
    "    parser.add_argument('--unscale-lr', action='store_true')\n",
    "\n",
    "    # Model parameters\n",
    "    parser.add_argument('--model', default='deit_base_patch16_224', type=str, metavar='MODEL',\n",
    "                        help='Name of model to train') # default='deit_base_patch16_224',\n",
    "    parser.add_argument('--input-size', default=224, type=int, help='images input size') #default=224\n",
    "\n",
    "    parser.add_argument('--drop', type=float, default=0.0, metavar='PCT',\n",
    "                        help='Dropout rate (default: 0.)')\n",
    "    parser.add_argument('--drop-path', type=float, default=0.1, metavar='PCT',\n",
    "                        help='Drop path rate (default: 0.1)')\n",
    "\n",
    "    parser.add_argument('--model-ema', action='store_true')\n",
    "    parser.add_argument('--no-model-ema', action='store_false', dest='model_ema')\n",
    "    parser.set_defaults(model_ema=True)\n",
    "    parser.add_argument('--model-ema-decay', type=float, default=0.99996, help='')\n",
    "    parser.add_argument('--model-ema-force-cpu', action='store_true', default=False, help='')\n",
    "\n",
    "    # Optimizer parameters\n",
    "    parser.add_argument('--opt', default='adamw', type=str, metavar='OPTIMIZER',\n",
    "                        help='Optimizer (default: \"adamw\"')\n",
    "    parser.add_argument('--opt-eps', default=1e-8, type=float, metavar='EPSILON',\n",
    "                        help='Optimizer Epsilon (default: 1e-8)')\n",
    "    parser.add_argument('--opt-betas', default=None, type=float, nargs='+', metavar='BETA',\n",
    "                        help='Optimizer Betas (default: None, use opt default)')\n",
    "    parser.add_argument('--clip-grad', type=float, default=None, metavar='NORM',\n",
    "                        help='Clip gradient norm (default: None, no clipping)')\n",
    "    parser.add_argument('--momentum', type=float, default=0.9, metavar='M',\n",
    "                        help='SGD momentum (default: 0.9)')\n",
    "    parser.add_argument('--weight-decay', type=float, default=0.05,\n",
    "                        help='weight decay (default: 0.05)')\n",
    "    # Learning rate schedule parameters\n",
    "    parser.add_argument('--sched', default='cosine', type=str, metavar='SCHEDULER',\n",
    "                        help='LR scheduler (default: \"cosine\"')\n",
    "    parser.add_argument('--lr', type=float, default=5e-4, metavar='LR',\n",
    "                        help='learning rate (default: 5e-4)')\n",
    "    parser.add_argument('--lr-noise', type=float, nargs='+', default=None, metavar='pct, pct',\n",
    "                        help='learning rate noise on/off epoch percentages')\n",
    "    parser.add_argument('--lr-noise-pct', type=float, default=0.67, metavar='PERCENT',\n",
    "                        help='learning rate noise limit percent (default: 0.67)')\n",
    "    parser.add_argument('--lr-noise-std', type=float, default=1.0, metavar='STDDEV',\n",
    "                        help='learning rate noise std-dev (default: 1.0)')\n",
    "    parser.add_argument('--warmup-lr', type=float, default=1e-6, metavar='LR',\n",
    "                        help='warmup learning rate (default: 1e-6)')\n",
    "    parser.add_argument('--min-lr', type=float, default=1e-5, metavar='LR',\n",
    "                        help='lower lr bound for cyclic schedulers that hit 0 (1e-5)')\n",
    "\n",
    "    parser.add_argument('--decay-epochs', type=float, default=30, metavar='N',\n",
    "                        help='epoch interval to decay LR')\n",
    "    parser.add_argument('--warmup-epochs', type=int, default=5, metavar='N',\n",
    "                        help='epochs to warmup LR, if scheduler supports')\n",
    "    parser.add_argument('--cooldown-epochs', type=int, default=10, metavar='N',\n",
    "                        help='epochs to cooldown LR at min_lr, after cyclic schedule ends')\n",
    "    parser.add_argument('--patience-epochs', type=int, default=10, metavar='N',\n",
    "                        help='patience epochs for Plateau LR scheduler (default: 10')\n",
    "    parser.add_argument('--decay-rate', '--dr', type=float, default=0.1, metavar='RATE',\n",
    "                        help='LR decay rate (default: 0.1)')\n",
    "\n",
    "    # Augmentation parameters\n",
    "    parser.add_argument('--color-jitter', type=float, default=0.3, metavar='PCT',\n",
    "                        help='Color jitter factor (default: 0.3)')\n",
    "    parser.add_argument('--aa', type=str, default='rand-m9-mstd0.5-inc1', metavar='NAME',\n",
    "                        help='Use AutoAugment policy. \"v0\" or \"original\". \" + \\\n",
    "                             \"(default: rand-m9-mstd0.5-inc1)'),\n",
    "    parser.add_argument('--smoothing', type=float, default=0.1, help='Label smoothing (default: 0.1)')\n",
    "    parser.add_argument('--train-interpolation', type=str, default='bicubic',\n",
    "                        help='Training interpolation (random, bilinear, bicubic default: \"bicubic\")')\n",
    "\n",
    "    parser.add_argument('--repeated-aug', action='store_true')\n",
    "    parser.add_argument('--no-repeated-aug', action='store_false', dest='repeated_aug')\n",
    "    parser.set_defaults(repeated_aug=True)\n",
    "    \n",
    "    parser.add_argument('--train-mode', action='store_true')\n",
    "    parser.add_argument('--no-train-mode', action='store_false', dest='train_mode')\n",
    "    parser.set_defaults(train_mode=True)\n",
    "    \n",
    "    parser.add_argument('--ThreeAugment', action='store_true') #3augment\n",
    "    \n",
    "    parser.add_argument('--src', action='store_true') #simple random crop\n",
    "    \n",
    "    # * Random Erase params\n",
    "    parser.add_argument('--reprob', type=float, default=0.25, metavar='PCT',\n",
    "                        help='Random erase prob (default: 0.25)')\n",
    "    parser.add_argument('--remode', type=str, default='pixel',\n",
    "                        help='Random erase mode (default: \"pixel\")')\n",
    "    parser.add_argument('--recount', type=int, default=1,\n",
    "                        help='Random erase count (default: 1)')\n",
    "    parser.add_argument('--resplit', action='store_true', default=False,\n",
    "                        help='Do not random erase first (clean) augmentation split')\n",
    "\n",
    "    # * Mixup params\n",
    "    parser.add_argument('--mixup', type=float, default=0.8,\n",
    "                        help='mixup alpha, mixup enabled if > 0. (default: 0.8)')\n",
    "    parser.add_argument('--cutmix', type=float, default=1.0,\n",
    "                        help='cutmix alpha, cutmix enabled if > 0. (default: 1.0)')\n",
    "    parser.add_argument('--cutmix-minmax', type=float, nargs='+', default=None,\n",
    "                        help='cutmix min/max ratio, overrides alpha and enables cutmix if set (default: None)')\n",
    "    parser.add_argument('--mixup-prob', type=float, default=1.0,\n",
    "                        help='Probability of performing mixup or cutmix when either/both is enabled')\n",
    "    parser.add_argument('--mixup-switch-prob', type=float, default=0.5,\n",
    "                        help='Probability of switching to cutmix when both mixup and cutmix enabled')\n",
    "    parser.add_argument('--mixup-mode', type=str, default='batch',\n",
    "                        help='How to apply mixup/cutmix params. Per \"batch\", \"pair\", or \"elem\"')\n",
    "\n",
    "    # Distillation parameters\n",
    "    parser.add_argument('--teacher-model', default='regnety_160', type=str, metavar='MODEL',\n",
    "                        help='Name of teacher model to train (default: \"regnety_160\"')\n",
    "    parser.add_argument('--teacher-path', type=str, default='')\n",
    "    parser.add_argument('--distillation-type', default='none', choices=['none', 'soft', 'hard'], type=str, help=\"\")\n",
    "    parser.add_argument('--distillation-alpha', default=0.5, type=float, help=\"\")\n",
    "    parser.add_argument('--distillation-tau', default=1.0, type=float, help=\"\")\n",
    "    \n",
    "    # * Cosub params\n",
    "    parser.add_argument('--cosub', action='store_true') \n",
    "    \n",
    "    # * Finetuning params\n",
    "    parser.add_argument('--finetune', default='', help='finetune from checkpoint')\n",
    "    parser.add_argument('--attn-only', action='store_true') \n",
    "    \n",
    "    # Dataset parameters\n",
    "    # parser.add_argument('--data-path', default='/datasets01/imagenet_full_size/061417/', type=str,\n",
    "    #                     help='dataset path')\n",
    "    # parser.add_argument('--data-set', default='IMNET', choices=['CIFAR', 'IMNET', 'INAT', 'INAT19'],\n",
    "    #                     type=str, help='Image Net dataset path')\n",
    "    parser.add_argument('--inat-category', default='name',\n",
    "                        choices=['kingdom', 'phylum', 'class', 'order', 'supercategory', 'family', 'genus', 'name'],\n",
    "                        type=str, help='semantic granularity')\n",
    "\n",
    "    parser.add_argument('--output_dir', default='',\n",
    "                        help='path where to save, empty for no saving')\n",
    "    # parser.add_argument('--device', default='cuda',\n",
    "    #                     help='device to use for training / testing')\n",
    "    parser.add_argument('--device', default='cpu',\n",
    "                        help='device to use for training / testing')\n",
    "    parser.add_argument('--seed', default=0, type=int)\n",
    "    parser.add_argument('--resume', default='', help='resume from checkpoint')\n",
    "    parser.add_argument('--start_epoch', default=0, type=int, metavar='N',\n",
    "                        help='start epoch')\n",
    "    parser.add_argument('--eval', action='store_true', help='Perform evaluation only')\n",
    "    parser.add_argument('--eval-crop-ratio', default=0.875, type=float, help=\"Crop ratio for evaluation\")\n",
    "    parser.add_argument('--dist-eval', action='store_true', default=False, help='Enabling distributed evaluation')\n",
    "    parser.add_argument('--num_workers', default=10, type=int)\n",
    "    parser.add_argument('--pin-mem', action='store_true',\n",
    "                        help='Pin CPU memory in DataLoader for more efficient (sometimes) transfer to GPU.')\n",
    "    parser.add_argument('--no-pin-mem', action='store_false', dest='pin_mem',\n",
    "                        help='')\n",
    "    parser.set_defaults(pin_mem=True)\n",
    "\n",
    "    # distributed training parameters\n",
    "    parser.add_argument('--distributed', action='store_true', default=False, help='Enabling distributed training')\n",
    "    parser.add_argument('--world_size', default=1, type=int,\n",
    "                        help='number of distributed processes')\n",
    "    parser.add_argument('--dist_url', default='env://', help='url used to set up distributed training')\n",
    "    \n",
    "    # amp about\n",
    "    parser.add_argument('--if_amp', action='store_true')\n",
    "    parser.add_argument('--no_amp', action='store_false', dest='if_amp')\n",
    "    parser.set_defaults(if_amp=False)\n",
    "\n",
    "    # if continue with inf\n",
    "    parser.add_argument('--if_continue_inf', action='store_true')\n",
    "    parser.add_argument('--no_continue_inf', action='store_false', dest='if_continue_inf')\n",
    "    parser.set_defaults(if_continue_inf=False)\n",
    "\n",
    "    # if use nan to num\n",
    "    parser.add_argument('--if_nan2num', action='store_true')\n",
    "    parser.add_argument('--no_nan2num', action='store_false', dest='if_nan2num')\n",
    "    parser.set_defaults(if_nan2num=False)\n",
    "\n",
    "    parser.add_argument('--nb_classes', default=2, type=int, help='Number of classes (cats and dogs)')\n",
    "\n",
    "    parser.add_argument('--local-rank', default=0, type=int)\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4566e822-e13e-4912-9783-cee9c0d05da9",
   "metadata": {},
   "source": [
    "### Dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957a9dbb-054f-4bff-b49e-3d6ece36f885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path where all images are stored\n",
    "image_path = \"C:/Users/mahagam3/Documents/ECE course/Project B/Mamba/Vision_mamba_code/cats_dogs\"\n",
    "\n",
    "# Collect all image paths (assuming images are .jpg or .png)\n",
    "image_files = [os.path.join(image_path, f) for f in os.listdir(image_path) if f.endswith(('.jpg', '.png'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc738c6d-7450-452a-bbb0-adcce39d8ff4",
   "metadata": {},
   "source": [
    "### Load images and extract patches + drop patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061ec2a8-62f9-4df6-88da-190010e96c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def load_images_and_extract_patches(image_folder, patch_size=16, drop_fraction=0.50): # change the drop_fraction to 0.0 to get all patches\n",
    "    patches = []\n",
    "    labels = []\n",
    "    \n",
    "    # Iterate over all image files in the folder\n",
    "    for image_file in os.listdir(image_folder):\n",
    "        if image_file.endswith(('.jpg', '.png')):\n",
    "            image_path = os.path.join(image_folder, image_file)\n",
    "            \n",
    "            # Open the image\n",
    "            image = Image.open(image_path)\n",
    "            image = image.convert('RGB')\n",
    "            \n",
    "            # Extract patches from the image\n",
    "            image_data = np.array(image)\n",
    "            h, w, _ = image_data.shape\n",
    "            image_patches = []\n",
    "            for i in range(0, h - patch_size, patch_size):\n",
    "                for j in range(0, w - patch_size, patch_size):\n",
    "                    patch = image_data[i:i+patch_size, j:j+patch_size]\n",
    "                    image_patches.append(patch)\n",
    "            \n",
    "            # Calculate number of patches to drop for this image\n",
    "            num_patches = len(image_patches)\n",
    "            num_patches_to_drop = int(num_patches * drop_fraction)\n",
    "            \n",
    "            # Shuffle patches and drop some of them\n",
    "            image_patches = np.array(image_patches)\n",
    "            indices = np.random.permutation(num_patches)\n",
    "            image_patches = image_patches[indices[:-num_patches_to_drop]]  # Keep the remaining patches\n",
    "            \n",
    "            # Add the remaining patches to the overall list\n",
    "            patches.extend(image_patches)\n",
    "            \n",
    "            # Extract label from the filename (e.g., 'cat 1' -> 'cat')\n",
    "            label = image_file.split()[0]  # This takes the first part of the filename\n",
    "            labels.extend([label] * len(image_patches))  # Repeat the label for each remaining patch\n",
    "    \n",
    "    # Convert to np.array if needed\n",
    "    patches = np.array(patches)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return patches, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f0421b-0476-4116-aa21-0bbddcf47cf3",
   "metadata": {},
   "source": [
    "### dataset building to set to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceea5a83-ba42-4600-b599-7a5f12cd5545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(is_train=True, patch_size=16, batch_size=64, patches=None, labels=None, drop_fraction=0.95): # adjust drop_fraction as needed\n",
    "    # Convert the patches list to a tensor\n",
    "    patches_tensor = torch.stack([torch.tensor(patch, dtype=torch.float32).unsqueeze(0) for patch in patches])\n",
    "\n",
    "    # Encode the labels if they are not already numeric\n",
    "    label_encoder = LabelEncoder()\n",
    "    labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "    # Convert the labels to a tensor\n",
    "    labels_tensor = torch.tensor(labels_encoded, dtype=torch.long)\n",
    "\n",
    "    # Create a dataset and dataloader\n",
    "    dataset = TensorDataset(patches_tensor, labels_tensor)\n",
    "\n",
    "    if is_train:\n",
    "        data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4, drop_last=True)\n",
    "    else:\n",
    "        data_loader = DataLoader(dataset, batch_size=batch_size // 2, shuffle=False, num_workers=4, drop_last=True)\n",
    "\n",
    "    return data_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c52ee03-e6bb-4e7f-82d7-631552c1c0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the FLOPs\n",
    "def calculate_flops(model, input_tensor):\n",
    "    from thop import profile\n",
    "    \n",
    "    # Clear any existing 'total_ops' and 'total_params' attributes\n",
    "    for layer in model.modules():\n",
    "        if hasattr(layer, 'total_ops'):\n",
    "            del layer.total_ops  # Remove existing 'total_ops'\n",
    "        if hasattr(layer, 'total_params'):\n",
    "            del layer.total_params  # Remove existing 'total_params'\n",
    "\n",
    "    # Now calculate FLOPs\n",
    "    flops, params = profile(model, inputs=(input_tensor,))\n",
    "    return flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05799a0-c86f-46e3-8656-a4b8e0fb56ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Main function\n",
    "def main(args):\n",
    "    # Use CPU only\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "    # Load image file paths and patches\n",
    "    image_folder = \"C:/Users/mahagam3/Documents/ECE course/Project B/Mamba/Vision_mamba_code/cats_dogs\"\n",
    "\n",
    "    # Load patches and labels directly, applying the drop_fraction\n",
    "    print(\"Loading dataset...\")\n",
    "    patches, labels = load_images_and_extract_patches(image_folder)  \n",
    "\n",
    "    print(f\"Dataset loaded with {len(patches)} patches!\")\n",
    "\n",
    "    # Convert patches to tensor without resizing\n",
    "    patches_tensor = torch.stack([torch.tensor(patch, dtype=torch.float32).unsqueeze(0) for patch in patches])\n",
    "    print(patches_tensor.shape)\n",
    "\n",
    "    # Convert labels to tensor (ensure labels are integers)\n",
    "    if isinstance(labels[0], str):  # Check if labels are strings\n",
    "        label_map = {label: idx for idx, label in enumerate(set(labels))}\n",
    "        labels = [label_map[label] for label in labels]\n",
    "\n",
    "    labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    # Create dataset directly from the patches and labels\n",
    "    dataset_train = TensorDataset(patches_tensor, labels_tensor)\n",
    "\n",
    "    # DataLoader setup\n",
    "    data_loader_train = DataLoader(\n",
    "        dataset_train,\n",
    "        batch_size=args.batch_size,\n",
    "        num_workers=args.num_workers,\n",
    "        pin_memory=args.pin_mem,\n",
    "        drop_last=True,\n",
    "    )\n",
    "\n",
    "        # Create model\n",
    "    print(f\"Creating model: {args.model}\")\n",
    "    model = create_model(\n",
    "        args.model,\n",
    "        pretrained=False,\n",
    "        num_classes=1, #num_classes=args.nb_classes,\n",
    "        drop_rate=args.drop,\n",
    "        drop_path_rate=args.drop_path,\n",
    "        img_size=args.input_size\n",
    "    )\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # Measure FLOPs once after model initialization\n",
    "    size = int((len(patches) / 2000) * 0.5) # after dropping 50% of extratced 16x16 patches\n",
    "    input_tensor_data = torch.randn(size, 3, 224, 224) #input_tensor_data = torch.randn(len(patches), 3, 224, 224)\n",
    "    flops_count = calculate_flops(model, input_tensor_data)\n",
    "    print(f'FLOPs for Model: {flops_count:.2f} FLOPs')\n",
    "\n",
    "    # Optimizer and scheduler\n",
    "    optimizer = create_optimizer(args, model)\n",
    "    lr_scheduler, _ = create_scheduler(args, optimizer)\n",
    "\n",
    "    # Loss function\n",
    "    if args.nb_classes == 2:\n",
    "        # Binary classification: use BCEWithLogitsLoss\n",
    "        criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    else:\n",
    "        # Multi-class classification: use CrossEntropyLoss or LabelSmoothingCrossEntropy\n",
    "        if args.label_smoothing > 0.0:\n",
    "            criterion = LabelSmoothingCrossEntropy(smoothing=args.label_smoothing)\n",
    "        else:\n",
    "            criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # Start training\n",
    "    print(f\"Start training for {args.epochs} epochs\")\n",
    "    start_time = time.time()\n",
    "    total_training_flops = 0  # Variable to accumulate total FLOPs across all epochs\n",
    "\n",
    "    for epoch in range(args.start_epoch, args.epochs):\n",
    "        epoch_flops = 0  # Variable to accumulate FLOPs for the current epoch\n",
    "\n",
    "        # Train one epoch\n",
    "        for batch_idx, (inputs, targets) in enumerate(data_loader_train):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            inputs = inputs.squeeze(1) \n",
    "            inputs = inputs.permute(0, 3, 1, 2)\n",
    "            inputs = F.interpolate(inputs, size=(224, 224), mode='bilinear', align_corners=False)\n",
    "            # inputs = inputs.view(-1, 3, 224, 224) \n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            targets = targets.float().unsqueeze(1)\n",
    "\n",
    "            # Compute loss\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Track FLOPs during the forward pass for the current batch\n",
    "            batch_flops = flops_count  # Using the previously computed FLOPs\n",
    "            epoch_flops += batch_flops\n",
    "\n",
    "        # Update learning rate\n",
    "        lr_scheduler.step(epoch)\n",
    "\n",
    "        # Optionally, print FLOPs after each epoch\n",
    "        print(f\"Epoch {epoch + 1}: Total FLOPs for this epoch: {epoch_flops / 1e9:.2f} GFLOPs\")\n",
    "\n",
    "        # Accumulate total FLOPs for all epochs\n",
    "        total_training_flops += epoch_flops\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "    print(f'Training time: {total_time_str}')\n",
    "\n",
    "    # Print the total FLOPs for training\n",
    "    print(f\"Total training FLOPs: {total_training_flops / 1e9:.2f} GFLOPs\")  # Convert to GFLOPs for easier interpretation\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser('Training and evaluation script', parents=[get_args_parser()], conflict_handler='resolve')\n",
    "    args = parser.parse_args()\n",
    "    if args.output_dir:\n",
    "        Path(args.output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0e6c4a-7ea8-4328-b3bb-6fe589bdcf06",
   "metadata": {},
   "source": [
    "           ########################################### End of the code ################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
